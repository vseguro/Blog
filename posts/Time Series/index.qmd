---
title: "Homicidios en Medellín entre 2003 y 2022"
toc: true
toc-location: left
date: "Diciembre de 2022"
image: "image.jpg"
categories: [time series, code, analysis]
editor: source
---

---
```{r}
#| warning: false
#| message: false
library(kableExtra)
library(knitr)
library("data.table") 
library(dplyr)
library(tidyverse)
library(magrittr)
library(forecast)
library(TSstudio)
library(lmtest)
library(tseries)
library(TSA)
library(plotly)
library(gridExtra)
require(tsoutliers)
library(astsa)
```
---

## Marco teórico

La base de datos *homicidio.csv* encontrada en el portal [MEData](http://medata.gov.co/dataset/homicidio/resource/9813d08c-2e2b-4691-a651-34923a2ff00d#%7Bview-graph:%7BgraphOptions:%7Bhooks:%7BprocessOffset:%7B%7D,bindEvents:%7B%7D%7D%7D%7D,graphOptions:%7Bhooks:%7BprocessOffset:%7B%7D,bindEvents:%7B%7D%7D%7D%7D) contiene información acerca de los homicidios registrados por la mesa de revisión y validación de casos de homicidio en la ciudad de Medellín. Dicha base de datos en crudo contiene 19169 observaciones de 36 variables.

```{r}
homicidios <- read.csv("homicidio.csv", sep = ";")
```



```{r}
kable(head(homicidios[1:5,1:2]), caption = "Homicidios Medellín")
```



El interés se centra en estudiar el comportamiento de este suceso a lo largo del tiempo para determinar si existen épocas del año donde el número de homicidios aumente o muestre patrones.

## Lectura y limpieza de la base de datos:
\

-   Adecuación de la fecha:

```{r}
#| echo: true
homicidios$fecha_hecho <- substr(homicidios$fecha_hecho, 0, 7)
```
\

-   Conteo por mes de casos:

```{r}
#| echo: true
resumen_hom <- homicidios %>% group_by(fecha_hecho) %>% summarise(casos=sum(cantidad))
```
\

-   Generación de fechas:

```{r}
#| echo: true
resumen_hom$fecha <- seq(as.Date("2003-01-01"), by="month", len=236)
```


## Serie de tiempo: Casos de homicidio en Medellín:
\
\

```{r}
#|fig.align: 'center'
#|fig.width: 20 
#|fig.height: 15
serie <-resumen_hom %>% ggplot(aes(x=fecha, y=casos))+
  geom_line(col = "blue") + labs(x = "Fecha", y = "Número de homicidios")
ggplotly(serie)
```

#

```{r}
resumen_hom$mes <- month(resumen_hom$fecha)
resumen_hom$mes <- factor(month.abb[resumen_hom$mes],
                           levels = month.abb)

resum_1 <- resumen_hom %>% group_by(mes) %>%
  summarise(med_month = mean(casos),
            sd_month = sd(casos),
            mediana = median(casos))

g1 <- ggplot(resum_1, aes(x=mes, y=med_month))+
  geom_bar(stat="identity", col = "blue", fill = "cornflowerblue", alpha = 0.8) + labs(x = "Mes", y = "Promedio mensual de homicidios")+scale_y_continuous(breaks = c(0,20,40,60,80))

g2 <- ggplot(resum_1, aes(x=mes, y=mediana))+
  geom_bar(stat="identity", col = "blue", fill = "cornflowerblue", alpha = 0.8) + labs(x = "Mes", y = "Mediana mensual de homicidios")+scale_y_continuous(breaks = c(0,20,40,60,80,100))

grid.arrange(g1,g2,ncol = 2, nrow = 1)
```


# 

En la serie se observa una decaimiento en los primeros años, correspondientes a los años 2003-2004. Para inicios de 2009 el número de homicidios se dispara nuevamente hasta alcanzar un pico en enero de 2010 con un total de 239 homicidios registrados. De ahí en adelante empieza su descenso y parece estabilizarse en los últimos años. Además, con el gráfico de barras de las medianas por mes (dado que el promedio es más sensible a *outliers*) se observa que en el mes de junio en mediana se presentan mayor número de homicidios.

Por otro lado, con la gráfica de la serie de tiempo por si sola, dada la escala de los registros es díficil determinar si existe estacionalidad, por lo que se presentan los siguientes gráficos para el diagnóstico de esta:

```{r}
resumen_hom <-  resumen_hom[order(resumen_hom$fecha),]
```

# 


```{r}
homicidio <- ts(resumen_hom$casos, start = c(2003,1), end = c(2022,8), frequency = 12)
b <- ggseasonplot(homicidio, year.labels=TRUE,continuous=TRUE)
ggplotly(b)
```



# 


```{r}
ts_seasonal(homicidio, type="box")
```



# 


```{r}
ggseasonplot(homicidio, polar = TRUE)
```



## {.scrollable}

En los últimos gráficos se observa que la serie no presenta estacionalidad, es decir, los meses no están relacionados con el número de homicidios. Sin embargo, dada la escala y la presencia de *outliers*, no es fácil de manera gráfica detectar estacionalidad, por lo que previamente se ha convertido la serie en un objeto **ts** con frecuencia 12 y se aplica la función **auto.arima**.



```{r}
acf1 <- acf(homicidio, lag.max = 60)
pacf1 <- pacf(homicidio, lag.max = 60)
```



## Modelo a utilizar y alternativas
\

```{r}
#| echo: true
mod <- auto.arima(homicidio, stepwise = FALSE, approximation = FALSE)
summary(mod)
```

\

La función **auto.arima** arrojó como resultado un modelo $SARIMA(0,1,1) \times (1,0,0)_{12}$.

#

### Validación de supuestos:

Se procede a verificar el cumplimiento de los supuestos de este modelo:



```{r}
#|warning: FALSE
checkresiduals(mod$residuals)
```



#

#### Supuesto de normalidad:

\


```{r}
qqnorm(mod$residuals)
qqline(mod$residuals)
```



#

#### Pruebas analíticas
\
-   Prueba de *Ljung-Box*:

```{r}
Box.test(mod$residuals, lag = 20, type = "Ljung")
```

\

-   Prueba de *Jarque Bera*:

```{r}
jarque.bera.test(mod$residuals)
```

\

-   Prueba de *Shapiro-Wilk*:

```{r}
shapiro.test(mod$residuals)
```

#

Con un nivel de significancia del 5 %, dados los resultados anteriores, se concluye que los residuales del modelo no están autocorrelacionados, sin embargo estos no siguen una distribución normal.

Se procede ahora a modelar los valores *outliers* del modelo para luego proceder a hacer predicciones y ver si el comportamiento del año 2010 tiene un efecto sobre estas dado que se realizan más de 10 años después.

#

:::: {.columns}

::: {.column width="60%"}
```{r}
#| echo: true
#| results: hide
delta <- seq(0.1, 0.90, 0.05)
bic_1 <- vector()
ljungbox1 <- vector()
i = 0
for(d in delta){
  i = i+1
  modelo_outl <- tso(homicidio, delta=d)
  bic_1[i] <- modelo_outl$fit$bic
  ljungbox1[i] <- checkresiduals(modelo_outl$fit,
                                 plot = FALSE)$p.value
}
```
:::

:::{.column width="40%"}
```{r}
#| echo: true
which.min(bic_1)
delta[13]
ljungbox1[13]
```
:::

::::

#

\

```{r}
#| echo: true
mod_outliers <- tso(homicidio, delta = 0.7)
mod_outliers
```

\

Al modelar los *outliers* el modelo arrojado por la función **tso** es un $SARIMA(0,1,1) \times (2,0,0)_{12}$

---

Se modelan los *outliers* arrojados por la función **tso**.

```{r}
#| echo: true
modelo2 <- arimax(homicidio, order = c(0,1,1),
                  seasonal = list(order = c(2,0,0)),
                  xtransf = data.frame(abril2009 = 1*c(rep(0,75),rep(1,161)),
                                       febrero2010 =1*(seq_along(homicidio) == 86),
                                       septiembre2010 = 1*c(rep(0,92),rep(1,144)),
                                       septiembre2011 = 1*(seq_along(homicidio) == 105),
                                       enero2012 = 1*(seq_along(homicidio) == 109)),
                                       transfer=list(c(0, 0), c(1, 0), c(0,0), c(1, 0), c(1, 0)))
```

```{r}
#| echo: true
coeftest(modelo2)
```

#

Se procede entonces a ajustar el modelo con los parámetros significativos.

```{r}
#| echo: true
modelo_3 <- arimax(homicidio, order = c(0,1,1),
                              seasonal = list(order = c(2,0,0)),
                              xtransf = data.frame(febrero2010 =1*(seq_along(homicidio) == 86),
                                                   enero2012 = 1*(seq_along(homicidio) == 109)),
                              transfer=list(c(1, 0), c(0, 0)))
coeftest(modelo_3)
```

#

### Validación de supuestos.


```{r, results='hide'}
#|fig.width: 10
checkresiduals(modelo_3)
```


#

#### Supuesto de normalidad:


```{r}
qqnorm(modelo_3$residuals)
qqline(modelo_3$residuals)
```


#

#### Pruebas analíticas

-   Prueba de *Ljung-Box*:

```{r}
#| echo: true
Box.test(modelo_3$residuals, lag = 20, type = "Ljung")
```

\

-   Prueba de *Jarque Bera*:

```{r}
#| echo: true
jarque.bera.test(modelo_3$residuals)
```

\

-   Prueba de *Shapiro-Wilk*:

```{r}
#| echo: true
shapiro.test(modelo_3$residuals)
```

#

Con un nivel de significancia del 5 %, dados los resultados anteriores, se concluye que los residuales del modelo no están autocorrelacionados, sin embargo estos no siguen una distribución normal.


## Backtesting

Se procede a partir la base de datos en 2: la primera parte hasta agosto de 2021 para entrenamiento y el último año para testeo:

```{r}
#| echo: true
train <- window(homicidio, start = c(2003, 1), end = c(2021,8))
test <- window(homicidio, start = c(2021,9))
```

#

::: {.panel-tabset}

## Modelo 1

Ajustado con __auto.arima__ con los datos en la escala original:

```{r}
#| echo: true
modelo_train1 <- auto.arima(train, stepwise = F, approximation = F)
summary(modelo_train1)
```

## Modelo 2 {.scrollable}
Modelando los _outliers_ y con los datos en la escala original:

```{r}
#| echo: true
#| results: hide
delta <- seq(0.1, 0.90, 0.05)
aic_1 <- vector()
ljungbox1 <- vector()
i = 0
for(d in delta){
  i = i+1
  modelo_outl <- tso(train, delta=d)
  aic_1[i] <- modelo_outl$fit$aic
  ljungbox1[i] <- checkresiduals(modelo_outl$fit,
                                 plot = FALSE)$p.value
}
```

```{r}
#| echo: true
which.min(aic_1)
ljungbox1[12]
delta[12]
```

```{r}
#| echo: true
modelo_aux <- tso(train, delta = 0.65)
modelo_aux
```

```{r}
#| echo: true
modelo_aux <- arimax(train, order = c(0,1,1),
                  seasonal = list(order = c(2,0,0)),
                  xtransf = data.frame(abril2009 = 1*c(rep(0,75),rep(1,149)),
                                       febrero2010 =1*(seq_along(train) == 86),
                                       septiembre2010 = 1*c(rep(0,92),rep(1,132)),
                                       septiembre2011 = 1*(seq_along(train) == 105),
                                       enero2012 = 1*(seq_along(train) == 109)),
                                       transfer=list(c(0, 0), c(1, 0), c(0,0), c(1, 0), c(1, 0)))
coeftest(modelo_aux)
```

```{r}
#| echo: true
# Valores outliers significafivos
xreg <- cbind(I1=stats::filter(1*(seq.int(length(train) + 12) == 86),
                               filter=0.51358,method = "rec",
                               sides = 1))
xreg2 <- data.frame(TC86 = xreg, TC109 = 1*(seq.int(length(train) + 12) == 109))

modelo_train2 <- arima(train, order = c(2,1,0), seasonal = list(order=c(2,0,0)),
                    xreg = xreg2[1:224, ]) 

coeftest(modelo_train2)
```

## Modelo 3

Aplicando la transformación logaritmo:

```{r}
#| echo: true
modelo_train_log <- auto.arima(log(train), stepwise = F, approximation = F) 
summary(modelo_train_log)
```

## Modelo 4 {.scrollable}
Aplicando transformación logaritmo y modelando los _outliers_:

```{r}
#| echo: true
#| results: hide
delta <- seq(0.1, 0.90, 0.05)
aic_1 <- vector()
ljungbox1 <- vector()
i = 0
for(d in delta){
  i = i+1
  modelo_outl <- tso(log(train), delta=d)
  aic_1[i] <- modelo_outl$fit$aic
  ljungbox1[i] <- checkresiduals(modelo_outl$fit,
                                 plot = FALSE)$p.value
}
```

```{r}
#| echo: true
which.min(aic_1)
ljungbox1[1]
delta[1]
```


```{r}
#| echo: true
modelo_train2_log <- tso(log(train), delta = 0.1) 
modelo_train2_log 
```

Bajo la transformación logaritmo, la función __tso__ no detecta _outliers_, por lo que este modelo no será tenido en cuenta de aquí en adelante.

:::


## Predicciones para comparar modelos:

- Predicciones modelo 1:

```{r}
#| echo: true
npred <- 12
fore1 <- forecast(modelo_train1, h=npred)
```

\

- Predicciones modelo 2:

```{r}
#| echo: true
fore2 <- predict(modelo_train2, 12, newxreg = xreg2[225:236,])
```

\

- Predicciones modelo 3:

```{r}
#| echo: true
fore1_log <- forecast(modelo_train_log, h=npred)
```

## Medidas de error:

```{r}
#| echo: true
# Modelo 1:
accuracy(fore1$mean, test)
# Modelo 2:
accuracy(fore2$pred, test)
# Modelo 3:
accuracy(exp(fore1_log$mean), test)
```
Donde se obtiene que las medidas de errores son menores en el modelo 3, lo que indica que es el modelo más adecuado de los propuestos para modelar la serie de tiempo de homicidios en Medellín en la ventana de tiempo considerada.

#
### Gráfico de los valores ajustados para el entrenamiento:

\


```{r}
colores <- c("Observado" = "black","Modelo 1" = "blue", "Modelo 2" = "red", "Modelo 3" = "green")
```

```{r}
#| echo: true
df_train <- data.frame(fecha=resumen_hom$fecha[1:length(train)],
                       real=
                         resumen_hom$casos[1:length(train)],
                       pred1 = modelo_train1$fitted,
                       pred2 = fitted(modelo_train2),
                       pred3 = exp(modelo_train_log$fitted))
b <- df_train %>% ggplot(aes(x=fecha, y=real,colour="Observado"))+
  geom_line()+
  geom_line(aes(x=fecha, y=pred1, colour = "Modelo 1"),lty=2)+
  geom_line(aes(x=fecha, y=pred2, colour = "Modelo 2"), lty=3) + 
  geom_line(aes(x=fecha, y=pred3, colour = "Modelo 3"), lty=4) +
  labs(x = "Fecha", y = "Número de homicidios") +
     scale_color_manual(name = "", values = colores)+
  theme(legend.position = "bottom")
```

#

```{r}
ggplotly(b) %>% layout(legend = list(orientation = "h", x = 0.23, y =-0.13))
```


#
### Gráficos para los valores predichos para el test:

\

```{r}
#| echo: true
df_test<- data.frame(fecha=
                       resumen_hom$fecha[225:236],
                     real=
                       resumen_hom$casos[225:236],
                     pred1 = fore1$mean, pred2 = fore2$pred, pred3 = exp(fore1_log$mean),
                     li1=fore1$lower[,2], ls1=fore1$upper[,2],
                     li2=fore2$pred - 1.96*fore2$se, ls2 = fore2$pred + 1.96*fore2$se,
                     li3=exp(fore1_log$lower[,2]), ls3=exp(fore1_log$upper[,2]))

comp <- df_test %>% ggplot(aes(x=fecha, y=real, colour = "Observado"))+
  geom_line(lwd = 1)+
  geom_line(aes(x=fecha, y=pred1, colour = "Modelo 1"), lwd = 1)+
  geom_line(aes(x=fecha, y=li1,colour = "Modelo 1"), lty=2, lwd = 1)+
  geom_line(aes(x=fecha, y=ls1,colour = "Modelo 1"), lty=2, lwd = 1)+
  geom_line(aes(x=fecha, y=pred2, colour = "Modelo 2"), lty=3, lwd = 1.3)+
  geom_line(aes(x=fecha, y=li2,colour = "Modelo 2"), lty=3, lwd = 1)+
  geom_line(aes(x=fecha, y=ls2,colour = "Modelo 2"), lty=3, lwd = 1)+
  geom_line(aes(x=fecha, y=pred3, colour = "Modelo 3"), lty=4, lwd = 1.3)+
  geom_line(aes(x=fecha, y=li3,colour = "Modelo 3"), lty=4, lwd = 1)+
  geom_line(aes(x=fecha, y=ls3,colour = "Modelo 3"), lty=4, lwd = 1)+
  labs(x = "Fecha", y = "Número de homicidios") +
     scale_color_manual(name = "", values = colores)+
  theme(legend.position = "bottom")
```

#


```{r}
ggplotly(comp)%>% layout(legend = list(orientation = "h", x = 0.2, y =-0.13))
```

Se refuerza la conclusión de que el modelo más adecuado para modelar la serie de tiempo es el modelo 3: modelo con la transformación logaritmo, el cual cumple supuestos de normalidad y presenta menor medidas de error y el intervalo de predicción es más preciso en comparación con los otros dos modelos propuestos. Además se observa que modelar los _outliers_ no tiene influencia sobre las predicciones dado que después de tanto tiempo la recuperación gradual se vuelve casi cero.

# Resultados

## Predicciones

Se realizan predicciones para el próximo año con el modelo elegido como el más adecuado:

```{r}
#| echo: true
fore_final <- forecast(modelo_train_log, h=npred)
exp(fore_final$mean)
```

En promedio, se espera para diciembre de este año 30 homicidios en la ciudad de Medellín y para los meses de marzo a julio del próximo año se esperan aproximandamente 29 homicidios en la ciudad.

```{r}
df_fore <- data.frame(fecha=
                       seq(as.Date("2022-09-01"), by="month", len=12),
                     pred = exp(fore_final$mean),
                     li=exp(fore_final$lower[,2]), ls=exp(fore_final$upper[,2]))
```

#

```{r}
#| echo: true
colores_2 <- c("Observado" = "black", "Predicho" = "red", "Intervalo de predicción" = "blue")
pred_final <- ggplot(resumen_hom, aes(x=fecha, y=casos, colour = "Observado"))+ geom_line()+
geom_line(data=df_fore, aes(x=fecha, y=pred, colour = "Predicho"))+
geom_line(data=df_fore, aes(x=fecha, y=li, colour = "Intervalo de predicción"))+
geom_line(data=df_fore, aes(x=fecha, y=ls, colour = "Intervalo de predicción"))+
  labs(x = "Fecha", y = "Número de homicidios") +
     scale_color_manual(name = "", values = colores_2)+
  theme(legend.position = "bottom")
```

# 


```{r}
ggplotly(pred_final)%>% layout(legend = list(orientation = "h", x = 0.27, y =-0.15))
```

## Conclusiones y recomendaciones

- El efecto del comportamiento tan marcado en el número de homicidios que se presentó a inicios de 2003, finales de 2009 e inicios de 2010 no influye en la cantidad de homicidios que se puedan presentar en los próximos años.

- Los tres modelos presentado no parecen mostrar diferencias en las predicciones, pero sí lo hacen en los intervalos de predicción.
